# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rMgfS-rxfmjwHsYnKdp0oUr9NWVowR__
"""

import matplotlib.pyplot as plt
import cv2
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tkinter import *
from PIL import Image, ImageDraw
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout
from keras.optimizers import Adam
from keras.callbacks import ReduceLROnPlateau, EarlyStopping

data = pd.read_csv("handwritten.csv").astype("float32");
X = data.drop('0',axis = 1)
y = data['0']
X, y = shuffle(X, y, random_state=42)

word_dict = {0:'A', 1:'B', 2:'C', 3:'D', 4:'E', 5:'F', 6:'G', 7:'H', 8:'I', 9:'J',
             10:'K', 11:'L', 12:'M', 13:'N', 14:'O', 15:'P', 16:'Q', 17:'R', 18:'S',
             19:'T', 20:'U', 21:'V', 22:'W', 23:'X', 24:'Y', 25:'Z'}

y_int = np.int0(y)
count = np.zeros(26, dtype='int')
for i in y_int:
    count[i] += 1

alphabets = [value for key, value in word_dict.items()]
fig, ax = plt.subplots(1, 1, figsize=(9, 7))
ax.barh(alphabets, count)
plt.xlabel("Number of elements")
plt.ylabel("Alphabets")
plt.grid()
plt.show()

x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)
x_train = np.reshape(x_train.values, (x_train.shape[0], 28, 28, 1))
x_test = np.reshape(x_test.values, (x_test.shape[0], 28, 28, 1))

y_train_OHE = to_categorical(y_train, num_classes=26)
y_test_OHE = to_categorical(y_test, num_classes=26)

unlabeled_data = x_train[:2000]
labeled_data = x_train[2000:]
labeled_labels = y_train_OHE[2000:]

x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)
print("New shape of train data: ", x_train.shape)
x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)
print("New shape of train data: ", x_test.shape)

import time
start_time = time.time()
model = Sequential()
model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(MaxPool2D(pool_size=(2, 2), strides=2))
model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))
model.add(MaxPool2D(pool_size=(2, 2), strides=2))
model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='valid'))
model.add(MaxPool2D(pool_size=(2, 2), strides=2))
model.add(Flatten())
model.add(Dense(64, activation="relu"))
model.add(Dense(128, activation="relu"))
model.add(Dense(26, activation="softmax"))
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(labeled_data, labeled_labels, epochs=5, validation_data=(x_test, y_test_OHE))
pseudo_labels = model.predict(unlabeled_data)
pseudo_labels = np.argmax(pseudo_labels, axis=1)
confidence_threshold = 0.9
high_confidence_indices = np.max(model.predict(unlabeled_data), axis=1) >= confidence_threshold
pseudo_labeled_data = unlabeled_data[high_confidence_indices]
pseudo_labeled_labels = to_categorical(pseudo_labels[high_confidence_indices], num_classes=26)
combined_data = np.concatenate([labeled_data, pseudo_labeled_data], axis=0)
combined_labels = np.concatenate([labeled_labels, pseudo_labeled_labels], axis=0)
history = model.fit(combined_data, combined_labels, epochs=2, validation_data=(x_test, y_test_OHE))
time.sleep(2)
end_time = time.time()
elapsed_time = end_time - start_time
print(f"Elapsed time: {elapsed_time} seconds")

model.save('semi_supervised_handwritten_model.h5')
score = model.evaluate(x_test, y_test_OHE, verbose=0)
print("Loss:", score[0])
print("Accuracy:", score[1])
print(history.history.keys())
epochs = range(len(history.history['accuracy']))
plt.plot(epochs, history.history['accuracy'], label='Training Accuracy')
plt.plot(epochs, history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title("Training and Validation Accuracy per Epoch")
plt.show()

word_dict = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X', 24:'Y',25:'Z'}

model = keras.models.load_model('semi_supervised_handwritten_model.h5')
model.summary()
root = Tk()
canvas_width = 300
canvas_height = 300
canvas = Canvas(root, width=canvas_width, height=canvas_height, bg='white')
canvas.pack()
img = Image.new("RGB", (canvas_width, canvas_height), "white")
draw = ImageDraw.Draw(img)
last_x, last_y = None, None

def motion(event):
    global last_x, last_y
    x, y = event.x, event.y
    if last_x and last_y:
        canvas.create_line(last_x, last_y, x, y, width=10)
        draw.line((last_x, last_y, x, y), fill="black", width=10)
    last_x, last_y = x, y

def release(event):
    global last_x, last_y
    last_x, last_y = None, None

canvas.bind('<B1-Motion>', motion)
canvas.bind('<ButtonRelease-1>', release)
def save_image():
    resized_img = img.resize((280, 280))
    resized_img.save("drawn_image.jpg")

save_button = Button(root, text="Save Image", command=save_image)
save_button.pack()
def load_image():
    img = cv2.imread('drawn_image.jpg')
    img_copy = img.copy()
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (400,440))
    img_copy = cv2.GaussianBlur(img_copy, (7,7), 0)
    img_gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)
    _, img_thresh = cv2.threshold(img_gray, 100, 255, cv2.THRESH_BINARY_INV)
    img_final = cv2.resize(img_thresh, (28,28))
    img_final =np.reshape(img_final, (1,28,28,1))
    img_pred = word_dict[np.argmax(model.predict(img_final))]
    cv2.putText(img, "Image ", (20,25), cv2.FONT_HERSHEY_TRIPLEX, 0.7, color = (0,0,230))
    cv2.putText(img, "Prediction: " + img_pred, (20,410), cv2.FONT_HERSHEY_DUPLEX, 1.3, color = (255,0,30))
cv2.imshow('handwritten alphabet identification', img)
root.mainloop()
load_image()
cv2.waitKey(0)
cv2.destroyAllWindows()

